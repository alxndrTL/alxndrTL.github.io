main:

  - title: Linear attention kernel in ThunderKittens
    resume: A GPU kernel written in ThunderKittens (a wrapper on top of CUDA) that implements vanilla linear attention. It follows the chunkwise parallel algorithm as defined in [GLA](https://arxiv.org/abs/2312.06635).
    code: https://github.com/alxndrTL/ThunderKittens/blob/main/my_kernels/lin_attn/4090.cu
    image: ./assets/img/tk.jpeg
    date: Jan. 2025

  - title: OthelloMamba
    resume: Adapted the famous [OthelloGPT](https://arxiv.org/abs/2210.13382) experiment to show that it still holds with the Mamba architecture. [Personal recognition](https://github.com/alxndrTL/othello_mamba/issues/1) from Albert Gu.
    code: https://github.com/alxndrTL/othello_mamba
    image: ./assets/img/mamba_othello.png
    date: Feb. 2024

  - title: ChatGPT explained in 5 minutes (8 videos as of now)
    resume: As a micro-entrepreneur, I'm working with the [Flowers Inria lab](https://flowers.inria.fr/) on a video series explaining generative AI to a general audience. This work was used multiple times by the French administration for training of government officials.
    authors: Alexandre Torres-Leguet, Clément Romac, Thomas Carta, Pierre-Yves Oudeyer
    image: ./assets/img/chatgpt_5_min.png
    page: https://developmentalsystems.org/chatgpt_5_minutes/en/
    date: 2023 - now

  - title: Landing-Starships
    resume: Used RL to train rockets to land à la SpaceX in a 3D environment. A lot of trial and error with PPO in Unity ML-Agents. Curriculum learning to acheive the famous belly-flop maneuver.
    code: https://github.com/alxndrTL/Landing-Starships
    image: ./assets/img/starship.png
    date: Aug. 2020